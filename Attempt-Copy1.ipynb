{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37e51053-378c-4b5c-88ec-017c5943f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import neuralop\n",
    "import matplotlib.pyplot as plt\n",
    "import symengine as se\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc9fba6-1702-41e1-8a84-9fbe75bd3a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_transform(f, x):\n",
    "    return f((50*float(np.random.random() - 0.5)) * x + (float(np.random.random() - 0.5))) + (float(np.random.random() - 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53609f9c-9913-4c9c-bba8-af76f17aeb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_polynom(x):\n",
    "    degree = np.random.randint(1, 5)\n",
    "    expression = (float(np.random.random() - 0.5)) * x**degree\n",
    "    degree -= 1\n",
    "    while degree >= 0:\n",
    "        expression += 0.001*(float(np.random.random() - 0.5)) * x**degree\n",
    "        degree -= 1\n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "9e734aa1-d428-46b0-b221-ffb730c68bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_log(x):\n",
    "    return (float(np.random.random() - 0.5)) * se.log(x + 1 + (float(np.random.random())))\n",
    "    \n",
    "def random_sqrt(x):\n",
    "    return (float(np.random.random() - 0.5)) * se.sqrt(x + 1 + (float(np.random.random())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "c06dbe05-53e8-46c8-b98c-93310cfb425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sum(l):\n",
    "    res = []\n",
    "    for f1 in l:\n",
    "        res.append((float(np.random.random() - 0.5)) * f1 + (float(np.random.random() - 0.5)) * np.random.choice(l))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "13ab77cc-b9a1-411f-8062-e70734d42b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_product(l):\n",
    "    res = []\n",
    "    for f1 in l:\n",
    "        res.append((float(np.random.random() - 0.5)) * f1 * (float(np.random.random() - 0.5)) * np.random.choice(l))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "023d37a8-c62f-45d6-b8a7-cae0bd3fae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_function(x, num_points, length):\n",
    "    maximum = 10\n",
    "    minimum = -10\n",
    "    while maximum >= 10 or minimum <= -10 or np.abs(np.max(f_eval)-np.min(f_eval)) <= 10e-2:\n",
    "        bases = np.random.choice([random_transform(se.sin, x),\n",
    "                                  random_transform(se.cos, x),\n",
    "                                  random_transform(se.sinh, x),\n",
    "                                  random_transform(se.cosh, x),\n",
    "                                  random_log(x),\n",
    "                                  random_sqrt(x),\n",
    "                                  random_polynom(x)], size=np.random.randint(1, 5))\n",
    "        f = bases[0]\n",
    "        for i in range(1, len(bases)):\n",
    "            if np.random.random() < 0.5:\n",
    "                f = random_sum([f, bases[i]])[0]\n",
    "            else:\n",
    "                f = random_product([f, bases[i]])[0]\n",
    "        df = se.diff(f, x)\n",
    "        start = np.random.random()-1\n",
    "        end = start + length\n",
    "        points = np.sort(np.random.uniform(start, end, size=num_points))\n",
    "        f_eval = np.array([float(f.subs({x: p})) for p in points]) + np.random.normal(0, 1e-2, size=num_points)\n",
    "        df_eval = np.array([float(df.subs({x: p})) for p in points])\n",
    "        maximum = np.max([np.max(f_eval), np.max(df_eval)])\n",
    "        minimum = np.min([np.min(f_eval), np.min(df_eval)])\n",
    "    return f, df, points, f_eval, df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "41a270d2-e3bd-4108-9fe3-75e01e2a1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = int(2**14)\n",
    "length = 3\n",
    "num_points = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "4b77dac3-7457-464f-ac99-cbe7e60ba23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 16384 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06520375ad149799cc4d94df23c5b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16384 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GENERATING = True\n",
    "\n",
    "if GENERATING:\n",
    "    print(\"Generating\", total_size, \"samples\")\n",
    "    x = se.Symbol('x')\n",
    "\n",
    "    functions, derivatives, points, functions_eval, derivatives_eval = [], [], [], [], []\n",
    "    for _ in tqdm(range(total_size)):\n",
    "        f, df, p, f_e, df_e = random_function(x, num_points, length)\n",
    "        functions.append(f)\n",
    "        derivatives.append(df)\n",
    "        points.append(p)\n",
    "        functions_eval.append(f_e)\n",
    "        derivatives_eval.append(df_e)\n",
    "    X = np.array(list(zip(functions_eval, points)))\n",
    "    Y = np.array(derivatives_eval)\n",
    "    np.save(\"X.npy\", X)\n",
    "    np.save(\"Y.npy\", Y)\n",
    "else:\n",
    "    X, Y = np.load(\"X.npy\"), np.load(\"Y.npy\")\n",
    "    total_size, _, num_points = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "845a079e-a6e5-4165-9951-5df1b5c010d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(X.shape[0]*0.5)\n",
    "val_size = int(X.shape[0]*0.25)\n",
    "test_size = X.shape[0] - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a43ce650-a100-4240-b2bc-623ebca3b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = torch.tensor(X[:train_size], dtype=torch.float32), torch.tensor(Y[:train_size], dtype=torch.float32)\n",
    "x_val, y_val = torch.tensor(X[train_size:train_size+val_size], dtype=torch.float32), torch.tensor(Y[train_size:train_size+val_size], dtype=torch.float32)\n",
    "x_test, y_test = torch.tensor(X[train_size+val_size:], dtype=torch.float32), torch.tensor(Y[train_size+val_size:], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "6a77ca64-90f1-46ee-845c-3423e7743154",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi_0 = x_train[:, 0].max()\n",
    "mini_0 = x_train[:, 0].min()\n",
    "maxi_1 = x_train[:, 1].max()\n",
    "mini_1 = x_train[:, 1].min()\n",
    "\n",
    "x_train[:, 0] = (x_train[:, 0]-mini_0)/(maxi_0-mini_0)\n",
    "x_train[:, 1] = (x_train[:, 1]-mini_1)/(maxi_1-mini_1)\n",
    "\n",
    "x_val[:, 0] = (x_val[:, 0]-mini_0)/(maxi_0-mini_0)\n",
    "x_val[:, 1] = (x_val[:, 1]-mini_1)/(maxi_1-mini_1)\n",
    "\n",
    "x_test[:, 0] = (x_test[:, 0]-mini_0)/(maxi_0-mini_0)\n",
    "x_test[:, 1] = (x_test[:, 1]-mini_1)/(maxi_1-mini_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "2fd73a9d-4590-4e3a-8f7f-5ced089ad4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_y, min_y = torch.max(y_train), torch.min(y_train)\n",
    "y_train = (y_train-min_y)/(max_y-min_y)\n",
    "y_val = (y_val-min_y)/(max_y-min_y)\n",
    "y_test = (y_test-min_y)/(max_y-min_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "900f76a1-4447-4bec-8572-1cb798851f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 128\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "1459abc7-909d-4181-a9ec-e2e83ddf8475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3584\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = nn.Linear(shape*2, 512)\n",
    "        self.l2 = nn.Linear(512, 256)\n",
    "        self.l3 = nn.Linear(256, 512)\n",
    "        self.l4 = nn.Linear(512, shape)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.l1(inputs.reshape((inputs.shape[0], -1))))\n",
    "        x = self.relu(self.l2(x))\n",
    "        x = self.relu(self.l3(x))\n",
    "        x = self.l4(x)\n",
    "        return x\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model1 = Model(num_points).to('mps')\n",
    "best_model1 = deepcopy(model1)\n",
    "print(\"Number of parameters:\", np.sum([len(i) for i in model1.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "efad717c-631b-4d24-b662-968302530264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b45d9890e94f7ba3c69e6b50a2e36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model1.parameters(), lr=0.0005)\n",
    "losses_nn = []\n",
    "for epoch in (pbar:=tqdm(range(n_epochs))):\n",
    "    model1.train()\n",
    "    optimizer.zero_grad()\n",
    "    for b in range(0, x_train.shape[0], batch_size):\n",
    "        predictions = model1(x_train[b: b+batch_size].to('mps')).to('cpu')\n",
    "        loss = criterion(predictions, y_train[b: b+batch_size])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model1.eval()\n",
    "    losses_nn.append(criterion(model1(x_val.to('mps')).to('cpu'), y_val).item())\n",
    "    pbar.set_description(f\"{losses_nn[-1]}\")\n",
    "    if losses_nn[-1] == min(losses_nn):\n",
    "        best_model1 = deepcopy(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "07d9e3bd-b7eb-4fb8-a121-241826a672e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test loss: 0.010781707242131233\n",
      "Best test loss: 0.010394170880317688\n"
     ]
    }
   ],
   "source": [
    "print(\"Final test loss:\", criterion(model1(x_test.to('mps')).to('cpu'), y_test).item())\n",
    "print(\"Best test loss:\", criterion(best_model1(x_test.to('mps')).to('cpu'), y_test).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "5f967ad3-3c21-4e42-8c33-611e8c3492f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1178\n"
     ]
    }
   ],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            neuralop.models.FNO1d(n_modes_height=128, n_layers=8, in_channels=2, out_channels=1, hidden_channels=8),\n",
    "            #neuralop.models.UNO(in_channels=2, out_channels=1, hidden_channels=4, uno_out_channels=[4,4,4,4], uno_n_modes=[[64],[64],[64],[64]], \n",
    "            #                    uno_scalings=[[1],[1],[1],[1]])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        return self.fc(x)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model2 = Model2().to('mps')\n",
    "best_model2 = deepcopy(model2)\n",
    "print(\"Number of parameters:\", np.sum([len(i) for i in model2.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f9308-de68-4655-b85f-8be8e446398a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7c09d37732429eafa9164a5ac51f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model2.parameters(), lr=0.0005)\n",
    "losses = []\n",
    "for epoch in (pbar:=tqdm(range(n_epochs))):\n",
    "    model2.train()\n",
    "    optimizer.zero_grad()\n",
    "    for b in range(0, x_train.shape[0], batch_size):\n",
    "        predictions = model2(x_train[b: b+batch_size].unsqueeze(1).to('mps')).to('cpu')\n",
    "        loss = criterion(predictions.squeeze(), y_train[b: b+batch_size])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model2.eval()\n",
    "    losses.append(criterion(model2(x_test.unsqueeze(1).to('mps')).to('cpu').squeeze(), y_test).item())\n",
    "    pbar.set_description(f\"{losses[-1]}\")\n",
    "    if losses[-1] == min(losses):\n",
    "        best_model2 = deepcopy(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2c5a5-18a7-44ba-a864-ca6f4297a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final test loss:\", criterion(model2.to('cpu')(x_test).squeeze(), y_test).item())\n",
    "print(\"Best test loss:\", criterion(best_model2.to('cpu')(x_test).squeeze(), y_test).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc1371-361e-4550-8628-ffc70effa492",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "model2.eval()\n",
    "r = 4\n",
    "for i in [r, r+1]:\n",
    "    with torch.no_grad():\n",
    "        y_hat_nn, y_hat_no = best_model1(x_test[i:i+1].to('mps')).to('cpu').squeeze(), best_model2(x_test[i:i+1]).squeeze()\n",
    "    y_hat_np = np.diff((x_test[i, 0]+mini_0)*(maxi_0-mini_0))/(length/num_points)\n",
    "    y_hat_np = (y_hat_np-min_y.item())/(max_y.item()-min_y.item())\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(18, 4))\n",
    "    ax[0].plot(x_test[i, 1], y_test[i], linestyle=\"--\", label='truth')\n",
    "    ax[1].plot(x_test[i, 1], y_test[i], linestyle=\"--\", label='truth')\n",
    "    ax[2].plot(x_test[i, 1], y_test[i], linestyle=\"--\", label='truth')\n",
    "    ax[0].plot(x_test[i, 1], y_hat_nn, label='nn')\n",
    "    ax[1].plot(x_test[i, 1], y_hat_no, label='no')\n",
    "    ax[2].plot(x_test[i, 1, 1:], y_hat_np, label='np')\n",
    "    ax[0].grid('on'), ax[1].grid('on'), ax[2].grid('on')\n",
    "    ax[0].set_title('Neural Network'), ax[1].set_title('Neural Operator'), ax[2].set_title('Numerical differentiation')\n",
    "    ax[0].legend(), ax[1].legend(), ax[2].legend()\n",
    "    plt.show()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b083a5-5c9e-40b2-9181-8ac2794b13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(losses_nn, label='nn')\n",
    "plt.plot(losses, label='no')\n",
    "plt.title(f\"Neural Network ({sum([sum(p.shape) for p in model1.parameters()])} parameters): {np.mean(losses_nn[-20:]) : .7f}\\n\" +\n",
    "          f\"Neural Operator ({sum([sum(p.shape) for p in model2.parameters()])} parameters): {np.mean(losses[-20:]) : .7f}\")\n",
    "plt.yscale('log')\n",
    "plt.grid('on')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9865bd84-e2e5-4976-96d5-e3d1e47cfe81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
