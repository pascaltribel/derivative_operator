{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be557d5-d921-411f-a3d8-d10890f56847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import neuralop\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import symengine as se\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed\n",
    "import scipy\n",
    "from time import time\n",
    "import colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "177e6551-8ed6-45e8-9a3d-bce3e1567c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, n_epochs, batch_size):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    val_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for b in range(0, x_train.shape[0], batch_size):\n",
    "            batch_x = x_train[b:b + batch_size]\n",
    "            batch_y = y_train[b:b + batch_size]\n",
    "            predictions = model(batch_x, batch_y[:, 1])\n",
    "            loss = criterion(predictions, batch_y[:, 0])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = criterion(model(x_val, y_val[:, 1]), y_val[:, 0]).item()\n",
    "        val_losses.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "    return val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c37f180-ebcd-4668-94bd-face93893b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.load(\"X.npy\"), np.load(\"Y.npy\")\n",
    "total_size, _, num_points = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5aeb892-78cf-4791-bef0-46310d5545b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(X.shape[0]*0.5)\n",
    "val_size = int(X.shape[0]*0.25)\n",
    "test_size = X.shape[0] - train_size - val_size\n",
    "\n",
    "x_train, y_train = torch.tensor(X[:train_size], dtype=torch.float32).to('mps'), torch.tensor(Y[:train_size], dtype=torch.float32).to('mps')\n",
    "x_val, y_val = torch.tensor(X[train_size:train_size+val_size], dtype=torch.float32).to('mps'), torch.tensor(Y[train_size:train_size+val_size], dtype=torch.float32).to('mps')\n",
    "x_test, y_test = torch.tensor(X[train_size+val_size:], dtype=torch.float32).to('mps'), torch.tensor(Y[train_size+val_size:], dtype=torch.float32).to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2071696f-6390-4c54-aa78-639e07ad4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi_0 = x_train[:, 0].max()\n",
    "mini_0 = x_train[:, 0].min()\n",
    "maxi_1 = x_train[:, 1].max()\n",
    "mini_1 = x_train[:, 1].min()\n",
    "\n",
    "x_train[:, 0] = (x_train[:, 0]-mini_0)/(maxi_0-mini_0)\n",
    "x_train[:, 1] = (x_train[:, 1]-mini_1)/(maxi_1-mini_1)\n",
    "\n",
    "x_val[:, 0] = (x_val[:, 0]-mini_0)/(maxi_0-mini_0)\n",
    "x_val[:, 1] = (x_val[:, 1]-mini_1)/(maxi_1-mini_1)\n",
    "\n",
    "x_test[:, 0] = (x_test[:, 0]-mini_0)/(maxi_0-mini_0)\n",
    "x_test[:, 1] = (x_test[:, 1]-mini_1)/(maxi_1-mini_1)\n",
    "\n",
    "maxi_0_y = y_train[:, 0].max()\n",
    "mini_0_y = y_train[:, 0].min()\n",
    "maxi_1_y = y_train[:, 1].max()\n",
    "mini_1_y = y_train[:, 1].min()\n",
    "\n",
    "y_train[:, 0] = (y_train[:, 0]-mini_0_y)/(maxi_0_y-mini_0_y)\n",
    "y_train[:, 1] = (y_train[:, 1]-mini_1_y)/(maxi_1_y-mini_1_y)\n",
    "\n",
    "y_val[:, 0] = (y_val[:, 0]-mini_0_y)/(maxi_0_y-mini_0_y)\n",
    "y_val[:, 1] = (y_val[:, 1]-mini_1_y)/(maxi_1_y-mini_1_y)\n",
    "\n",
    "y_test[:, 0] = (y_test[:, 0]-mini_0_y)/(maxi_0_y-mini_0_y)\n",
    "y_test[:, 1] = (y_test[:, 1]-mini_1_y)/(maxi_1_y-mini_1_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63bc9cb7-3e96-4eea-a3a7-584448b424b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralOperator(nn.Module):\n",
    "    def __init__(self, n_modes_height=64, n_layers=1, hidden_channels=16):\n",
    "        super(NeuralOperator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            neuralop.models.FNO1d(n_modes_height=n_modes_height, n_layers=n_layers, in_channels=3, out_channels=1, hidden_channels=hidden_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, query):\n",
    "        inputs = inputs.view(inputs.size(0), -1, query.size(-1))\n",
    "        return self.fc(torch.concat([inputs, query.unsqueeze(1)], 1)).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88c4337f-5958-47f0-b369-563d88f1f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 32\n",
    "batch_size = 128\n",
    "exp = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b370b95-81b8-4f8b-9d1a-e40d71820753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode\t\tLayer\t\tChannel\t\tAverage\t\tStd\t\tTime\n",
      "8\t\t1\t\t4\t\t\u001b[32m0.02020\u001b[37m\t\t0.00059\t\t110.458\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmanual_seed(i)\n\u001b[1;32m     10\u001b[0m     neural_operator \u001b[38;5;241m=\u001b[39m NeuralOperator(n_modes_height\u001b[38;5;241m=\u001b[39mmode, n_layers\u001b[38;5;241m=\u001b[39mlayer, hidden_channels\u001b[38;5;241m=\u001b[39mchannel)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     losses_neural_operator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneural_operator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     errors[(mode, layer, channel)]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mmin\u001b[39m(losses_neural_operator))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(errors[(mode, layer, channel)]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mmin\u001b[39m([np\u001b[38;5;241m.\u001b[39mmean(errors[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m errors]):\n",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, n_epochs, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 18\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[1;32m     20\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "print(f\"Mode\\t\\tLayer\\t\\tChannel\\t\\tAverage\\t\\tStd\\t\\tTime\")\n",
    "for layer in [1, 4]:\n",
    "    for channel in [4, 12, 16]:\n",
    "        for mode in [8, 16, 32, 128]:\n",
    "            begin = time()\n",
    "            errors[(mode, layer, channel)] = []\n",
    "            for i in range(exp):\n",
    "                torch.manual_seed(i)\n",
    "                neural_operator = NeuralOperator(n_modes_height=mode, n_layers=layer, hidden_channels=channel).to('mps')\n",
    "                losses_neural_operator = train(neural_operator, epochs, batch_size)\n",
    "                errors[(mode, layer, channel)].append(min(losses_neural_operator))\n",
    "            if np.mean(errors[(mode, layer, channel)]) == min([np.mean(errors[i]) for i in errors]):\n",
    "                print(f\"{mode}\\t\\t{layer}\\t\\t{channel}\\t\\t{colorama.Fore.GREEN}{np.mean(errors[(mode, layer, channel)]):.5f}{colorama.Fore.WHITE}\\t\\t{np.std(errors[(mode, layer, channel)]):.5f}\\t\\t{time()-begin:.3f}\")\n",
    "            else:\n",
    "                print(f\"{mode}\\t\\t{layer}\\t\\t{channel}\\t\\t{np.mean(errors[(mode, layer, channel)]):.5f}\\t\\t{np.std(errors[(mode, layer, channel)]):.5f}\\t\\t{time()-begin:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3143e8ab-a4da-4f8f-9868-91deef629077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(errors, orient='index')\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = ['Key', '0', '1', '2', '3', '4']\n",
    "df[['Modes', 'Layers', 'Channels']] = pd.DataFrame(df['Key'].tolist(), index=df.index)\n",
    "df = df.drop(columns='Key')\n",
    "df_long = pd.melt(\n",
    "    df,\n",
    "    id_vars=['Modes', 'Layers', 'Channels'],\n",
    "    value_vars=['0', '1', '2', '3', '4'],\n",
    "    var_name='Value_Index',\n",
    "    value_name='Value'\n",
    ")\n",
    "df_long = df_long.drop(columns='Value_Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9027979-c3eb-4a63-9dcc-27b779b49b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
